{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender,Age and Ethnicity Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display, Image\n",
    "from glob import glob\n",
    "import PIL\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Gender_Detection\n"
     ]
    }
   ],
   "source": [
    "cd Gender_Detection/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying images in test/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arman\\Anaconda3\\envs\\capstone_demo\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.22.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Arman\\Anaconda3\\envs\\capstone_demo\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.22.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\n",
      " 14%|#4        | 1/7 [00:02<00:15,  2.62s/it]\n",
      " 29%|##8       | 2/7 [00:15<00:29,  5.84s/it]\n",
      " 43%|####2     | 3/7 [00:18<00:19,  4.90s/it]\n",
      " 57%|#####7    | 4/7 [00:28<00:19,  6.48s/it]\n",
      " 71%|#######1  | 5/7 [00:36<00:13,  6.74s/it]\n",
      " 86%|########5 | 6/7 [00:40<00:05,  5.97s/it]\n",
      "100%|##########| 7/7 [00:44<00:00,  5.30s/it]\n",
      "100%|##########| 7/7 [00:44<00:00,  6.30s/it]\n"
     ]
    }
   ],
   "source": [
    "!python pred.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arman\\Desktop\\Capstone_Demo\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving Output Images to Person Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import shutil\n",
    "\n",
    "src = \"C:\\\\Users\\\\Arman\\\\Desktop\\\\Capstone_Demo\\\\Gender_Detection\\\\results\\\\\"\n",
    "dst = \"C:\\\\Users\\\\Arman\\\\Desktop\\\\Capstone_Demo\\\\Person_Detection\\\\data\\\\demo\\\\\"\n",
    "\n",
    "files = [i for i in os.listdir(src) if i.endswith(\".jpg\") and path.isfile(path.join(src, i))]\n",
    "for f in files:\n",
    "    shutil.copy(path.join(src, f), dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\n"
     ]
    }
   ],
   "source": [
    "cd Person_Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running Person Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded network output\\vgg16\\voc_2007_trainval\\default\\vgg16_faster_rcnn_iter_65000.ckpt\n",
      "['03.jpg', '13.jpg', '28.jpg', '30.jpg', '36.jpg', '53.jpg', '56.jpg', 'image1.jpg', 'image10.jpg', 'image11.jpg', 'image12.jpg', 'image13.jpg', 'image14.jpg', 'image15.jpg', 'image16.jpg', 'image17.jpg', 'image18.jpg', 'image19.jpg', 'image2.jpg', 'image20.jpg', 'image21.jpg', 'image22.jpg', 'image23.jpg', 'image24.jpg', 'image25.jpg', 'image26.jpg', 'image27.jpg', 'image28.jpg', 'image29.jpg', 'image3.jpg', 'image30.jpg', 'image31.jpg', 'image32.jpg', 'image33.jpg', 'image34.jpg', 'image35.jpg', 'image36.jpg', 'image37.jpg', 'image38.jpg', 'image39.jpg', 'image4.jpg', 'image40.jpg', 'image41.jpg', 'image42.jpg', 'image43.jpg', 'image44.jpg', 'image45.jpg', 'image46.jpg', 'image47.jpg', 'image48.jpg', 'image5.jpg', 'image6.jpg', 'image7.jpg', 'image8.jpg', 'image9.jpg', 'video.mp4']\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/03.jpg\n",
      "Detection took 2.742s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/13.jpg\n",
      "Detection took 2.658s for 20 object classes\n",
      "person : 21\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From ./tools/demo.py:156: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From ./tools/demo.py:160: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2020-10-09 13:42:13.812279: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "WARNING:tensorflow:From C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\nets\\network.py:388: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\nets\\network.py:413: The name tf.no_regularizer is deprecated. Please use tf.compat.v1.no_regularizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\nets\\vgg16.py:27: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Arman\\Anaconda3\\envs\\capstone_demo\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\nets\\network.py:213: The name tf.ceil is deprecated. Please use tf.math.ceil instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\nets\\network.py:213: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\layer_utils\\proposal_layer.py:75: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\nets\\network.py:155: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From C:\\Users\\Arman\\Anaconda3\\envs\\capstone_demo\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\nets\\network.py:425: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From ./tools/demo.py:170: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "./tools/demo.py:59: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(figsize=(12, 12))\n",
      "Traceback (most recent call last):\n",
      "  File \"./tools/demo.py\", line 182, in <module>\n",
      "    demo(sess, net, im_name)\n",
      "  File \"./tools/demo.py\", line 97, in demo\n",
      "    scores, boxes = im_detect(sess, net, im)\n",
      "  File \"C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\model\\test.py\", line 87, in im_detect\n",
      "    blobs, im_scales = _get_blobs(im)\n",
      "  File \"C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\model\\test.py\", line 63, in _get_blobs\n",
      "    blobs['data'], im_scale_factors = _get_image_blob(im)\n",
      "  File \"C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\model\\test.py\", line 35, in _get_image_blob\n",
      "    im_orig = im.astype(np.float32, copy=True)\n",
      "AttributeError: 'NoneType' object has no attribute 'astype'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Demo for data/demo/28.jpg\n",
      "Detection took 4.663s for 20 object classes\n",
      "person : 5\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/30.jpg\n",
      "Detection took 3.858s for 20 object classes\n",
      "person : 16\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/36.jpg\n",
      "Detection took 3.885s for 20 object classes\n",
      "person : 13\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/53.jpg\n",
      "Detection took 3.843s for 20 object classes\n",
      "person : 5\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/56.jpg\n",
      "Detection took 4.095s for 20 object classes\n",
      "person : 5\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image1.jpg\n",
      "Detection took 4.013s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image10.jpg\n",
      "Detection took 3.853s for 20 object classes\n",
      "person : 7\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image11.jpg\n",
      "Detection took 4.010s for 20 object classes\n",
      "person : 5\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image12.jpg\n",
      "Detection took 3.948s for 20 object classes\n",
      "person : 5\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image13.jpg\n",
      "Detection took 3.992s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image14.jpg\n",
      "Detection took 3.808s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image15.jpg\n",
      "Detection took 3.877s for 20 object classes\n",
      "person : 1\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image16.jpg\n",
      "Detection took 3.916s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image17.jpg\n",
      "Detection took 3.849s for 20 object classes\n",
      "person : 5\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image18.jpg\n",
      "Detection took 3.859s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image19.jpg\n",
      "Detection took 4.309s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image2.jpg\n",
      "Detection took 4.218s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image20.jpg\n",
      "Detection took 4.478s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image21.jpg\n",
      "Detection took 4.224s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image22.jpg\n",
      "Detection took 4.278s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image23.jpg\n",
      "Detection took 4.027s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image24.jpg\n",
      "Detection took 4.007s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image25.jpg\n",
      "Detection took 4.320s for 20 object classes\n",
      "person : 1\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image26.jpg\n",
      "Detection took 6.523s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image27.jpg\n",
      "Detection took 4.254s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image28.jpg\n",
      "Detection took 4.703s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image29.jpg\n",
      "Detection took 4.168s for 20 object classes\n",
      "person : 5\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image3.jpg\n",
      "Detection took 4.462s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image30.jpg\n",
      "Detection took 4.378s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image31.jpg\n",
      "Detection took 4.406s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image32.jpg\n",
      "Detection took 5.136s for 20 object classes\n",
      "person : 1\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image33.jpg\n",
      "Detection took 5.194s for 20 object classes\n",
      "person : 9\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image34.jpg\n",
      "Detection took 5.215s for 20 object classes\n",
      "person : 1\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image35.jpg\n",
      "Detection took 5.080s for 20 object classes\n",
      "person : 1\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image36.jpg\n",
      "Detection took 4.301s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image37.jpg\n",
      "Detection took 4.278s for 20 object classes\n",
      "person : 5\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image38.jpg\n",
      "Detection took 4.612s for 20 object classes\n",
      "person : 5\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/demo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image39.jpg\n",
      "Detection took 4.811s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image4.jpg\n",
      "Detection took 4.771s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image40.jpg\n",
      "Detection took 4.681s for 20 object classes\n",
      "person : 5\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image41.jpg\n",
      "Detection took 4.970s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image42.jpg\n",
      "Detection took 4.743s for 20 object classes\n",
      "person : 5\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image43.jpg\n",
      "Detection took 4.873s for 20 object classes\n",
      "person : 3\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image44.jpg\n",
      "Detection took 4.876s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image45.jpg\n",
      "Detection took 6.316s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image46.jpg\n",
      "Detection took 6.354s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image47.jpg\n",
      "Detection took 6.498s for 20 object classes\n",
      "person : 0\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image48.jpg\n",
      "Detection took 6.355s for 20 object classes\n",
      "person : 1\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image5.jpg\n",
      "Detection took 6.570s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image6.jpg\n",
      "Detection took 6.126s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image7.jpg\n",
      "Detection took 5.345s for 20 object classes\n",
      "person : 10\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image8.jpg\n",
      "Detection took 5.892s for 20 object classes\n",
      "person : 9\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image9.jpg\n",
      "Detection took 6.165s for 20 object classes\n",
      "person : 1\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/video.mp4\n",
      "[WinError 2] The system cannot find the file specified: 'Person_Detection'\n",
      "C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\n"
     ]
    }
   ],
   "source": [
    "cd Person_Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "directory = \"./results\"\n",
    "\n",
    "files_in_directory = os.listdir(directory)\n",
    "filtered_files = [file for file in files_in_directory if file.endswith(\".jpg\")]  #Deleting the csv files\n",
    "for file in filtered_files:\n",
    "\tpath_to_file = os.path.join(directory, file)\n",
    "\tos.remove(path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "directory = \"./data/demo\"\n",
    "\n",
    "files_in_directory = os.listdir(directory)\n",
    "filtered_files = [file for file in files_in_directory if file.endswith(\".jpg\")]  #Deleting the csv files\n",
    "for file in filtered_files:\n",
    "\tpath_to_file = os.path.join(directory, file)\n",
    "\tos.remove(path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arman\\Desktop\\Capstone_Demo\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video for Person "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\data\\demo\n"
     ]
    }
   ],
   "source": [
    "cd Person_Detection/data/demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vidcap = cv2.VideoCapture('video.mp4')\n",
    "def getFrame(sec):\n",
    "    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "    hasFrames,image = vidcap.read()\n",
    "    if hasFrames:\n",
    "        cv2.imwrite(\"image\"+str(count)+\".jpg\", image)     # save frame as JPG file\n",
    "    return hasFrames\n",
    "sec = 0\n",
    "frameRate = 4.0 #//it will capture image in each 0.5 second\n",
    "count=1\n",
    "success = getFrame(sec)\n",
    "while success:\n",
    "    count = count + 1\n",
    "    sec = sec + frameRate\n",
    "    sec = round(sec, 2)\n",
    "    success = getFrame(sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\n"
     ]
    }
   ],
   "source": [
    "cd ../../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running Person Detection Model on Video frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded network output\\vgg16\\voc_2007_trainval\\default\\vgg16_faster_rcnn_iter_65000.ckpt\n",
      "['image1.jpg', 'image10.jpg', 'image11.jpg', 'image12.jpg', 'image13.jpg', 'image14.jpg', 'image15.jpg', 'image16.jpg', 'image17.jpg', 'image18.jpg', 'image19.jpg', 'image2.jpg', 'image20.jpg', 'image21.jpg', 'image22.jpg', 'image23.jpg', 'image24.jpg', 'image25.jpg', 'image26.jpg', 'image27.jpg', 'image28.jpg', 'image29.jpg', 'image3.jpg', 'image30.jpg', 'image31.jpg', 'image32.jpg', 'image33.jpg', 'image34.jpg', 'image35.jpg', 'image36.jpg', 'image37.jpg', 'image38.jpg', 'image39.jpg', 'image4.jpg', 'image40.jpg', 'image41.jpg', 'image42.jpg', 'image43.jpg', 'image44.jpg', 'image45.jpg', 'image46.jpg', 'image47.jpg', 'image48.jpg', 'image5.jpg', 'image6.jpg', 'image7.jpg', 'image8.jpg', 'image9.jpg', 'video.mp4']\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image1.jpg\n",
      "Detection took 4.017s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image10.jpg\n",
      "Detection took 3.805s for 20 object classes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From ./tools/demo.py:156: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From ./tools/demo.py:160: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2020-10-09 13:23:00.633653: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "WARNING:tensorflow:From C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\nets\\network.py:388: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\nets\\network.py:413: The name tf.no_regularizer is deprecated. Please use tf.compat.v1.no_regularizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\nets\\vgg16.py:27: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Arman\\Anaconda3\\envs\\capstone_demo\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\nets\\network.py:213: The name tf.ceil is deprecated. Please use tf.math.ceil instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\nets\\network.py:213: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\layer_utils\\proposal_layer.py:75: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\nets\\network.py:155: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From C:\\Users\\Arman\\Anaconda3\\envs\\capstone_demo\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\nets\\network.py:425: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From ./tools/demo.py:170: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "./tools/demo.py:59: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(figsize=(12, 12))\n",
      "Traceback (most recent call last):\n",
      "  File \"./tools/demo.py\", line 182, in <module>\n",
      "    demo(sess, net, im_name)\n",
      "  File \"./tools/demo.py\", line 97, in demo\n",
      "    scores, boxes = im_detect(sess, net, im)\n",
      "  File \"C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\model\\test.py\", line 87, in im_detect\n",
      "    blobs, im_scales = _get_blobs(im)\n",
      "  File \"C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\model\\test.py\", line 63, in _get_blobs\n",
      "    blobs['data'], im_scale_factors = _get_image_blob(im)\n",
      "  File \"C:\\Users\\Arman\\Desktop\\Capstone_Demo\\Person_Detection\\tools\\..\\lib\\model\\test.py\", line 35, in _get_image_blob"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person : 7\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image11.jpg\n",
      "Detection took 4.665s for 20 object classes\n",
      "person : 5\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image12.jpg\n",
      "Detection took 4.068s for 20 object classes\n",
      "person : 5\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image13.jpg\n",
      "Detection took 3.959s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image14.jpg\n",
      "Detection took 3.830s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image15.jpg\n",
      "Detection took 4.139s for 20 object classes\n",
      "person : 1\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image16.jpg\n",
      "Detection took 4.058s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image17.jpg\n",
      "Detection took 3.945s for 20 object classes\n",
      "person : 5\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image18.jpg\n",
      "Detection took 3.811s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image19.jpg\n",
      "Detection took 3.842s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image2.jpg\n",
      "Detection took 3.832s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image20.jpg\n",
      "Detection took 3.737s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image21.jpg\n",
      "Detection took 3.865s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image22.jpg\n",
      "Detection took 3.867s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image23.jpg\n",
      "Detection took 4.099s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image24.jpg\n",
      "Detection took 4.152s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image25.jpg\n",
      "Detection took 4.183s for 20 object classes\n",
      "person : 1\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image26.jpg\n",
      "Detection took 4.263s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image27.jpg\n",
      "Detection took 4.221s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image28.jpg\n",
      "Detection took 4.145s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image29.jpg\n",
      "Detection took 4.095s for 20 object classes\n",
      "person : 5\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image3.jpg\n",
      "Detection took 4.116s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image30.jpg\n",
      "Detection took 5.045s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image31.jpg\n",
      "Detection took 4.999s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image32.jpg\n",
      "Detection took 5.083s for 20 object classes\n",
      "person : 1\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image33.jpg\n",
      "Detection took 5.009s for 20 object classes\n",
      "person : 9\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image34.jpg\n",
      "Detection took 5.034s for 20 object classes\n",
      "person : 1\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image35.jpg\n",
      "Detection took 5.118s for 20 object classes\n",
      "person : 1\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image36.jpg\n",
      "Detection took 5.078s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image37.jpg\n",
      "Detection took 4.934s for 20 object classes\n",
      "person : 5\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image38.jpg\n",
      "Detection took 5.126s for 20 object classes\n",
      "person : 5\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image39.jpg\n",
      "Detection took 3.924s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image4.jpg\n",
      "Detection took 4.052s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image40.jpg\n",
      "Detection took 4.115s for 20 object classes\n",
      "person : 5\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image41.jpg\n",
      "Detection took 4.440s for 20 object classes\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image42.jpg\n",
      "Detection took 4.672s for 20 object classes\n",
      "person : 5\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image43.jpg\n",
      "Detection took 4.814s for 20 object classes\n",
      "person : 3\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image44.jpg\n",
      "Detection took 4.743s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image45.jpg\n",
      "Detection took 4.835s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image46.jpg\n",
      "Detection took 4.861s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image47.jpg\n",
      "Detection took 4.845s for 20 object classes\n",
      "person : 0\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image48.jpg\n",
      "Detection took 5.031s for 20 object classes\n",
      "person : 1\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image5.jpg\n",
      "Detection took 4.900s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image6.jpg\n",
      "Detection took 5.000s for 20 object classes\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image7.jpg\n",
      "Detection took 5.065s for 20 object classes\n",
      "person : 10\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image8.jpg\n",
      "Detection took 4.819s for 20 object classes\n",
      "person : 9\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/image9.jpg\n",
      "Detection took 4.772s for 20 object classes\n",
      "person : 1\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    im_orig = im.astype(np.float32, copy=True)\n",
      "AttributeError: 'NoneType' object has no attribute 'astype'\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/demo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                      Now Future Work Demo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
