{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arman05/Desktop/tf-faster-rcnn/Gender+Person\n"
     ]
    }
   ],
   "source": [
    "cd tf-faster-rcnn/Gender+Person/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arman05/Desktop\n"
     ]
    }
   ],
   "source": [
    "cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp ~/Desktop/Input_Test_Images/* ~/Desktop/face-classification/test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arman05/Desktop/face-classification\n"
     ]
    }
   ],
   "source": [
    "cd face-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arman05/anaconda3/envs/frcnn/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.22.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/arman05/anaconda3/envs/frcnn/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.22.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "classifying images in test/\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:16<00:00,  1.84s/it]\n"
     ]
    }
   ],
   "source": [
    "!python pred.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arman05/Desktop/face-classification/test\n"
     ]
    }
   ],
   "source": [
    "cd test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arman05/Desktop/face-classification\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arman05/Desktop/face-classification/results\n"
     ]
    }
   ],
   "source": [
    "cd results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "renamed '/home/arman05/Desktop/face-classification/results/10.csv' -> '/home/arman05/Desktop/tf-faster-rcnn/data/demo/10.csv'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/10.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/data/demo/10.jpg'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/11.csv' -> '/home/arman05/Desktop/tf-faster-rcnn/data/demo/11.csv'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/11.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/data/demo/11.jpg'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/12.csv' -> '/home/arman05/Desktop/tf-faster-rcnn/data/demo/12.csv'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/12.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/data/demo/12.jpg'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/13.csv' -> '/home/arman05/Desktop/tf-faster-rcnn/data/demo/13.csv'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/13.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/data/demo/13.jpg'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/14.csv' -> '/home/arman05/Desktop/tf-faster-rcnn/data/demo/14.csv'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/14.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/data/demo/14.jpg'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/15.csv' -> '/home/arman05/Desktop/tf-faster-rcnn/data/demo/15.csv'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/15.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/data/demo/15.jpg'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/16.csv' -> '/home/arman05/Desktop/tf-faster-rcnn/data/demo/16.csv'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/16.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/data/demo/16.jpg'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/17.csv' -> '/home/arman05/Desktop/tf-faster-rcnn/data/demo/17.csv'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/17.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/data/demo/17.jpg'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/18.csv' -> '/home/arman05/Desktop/tf-faster-rcnn/data/demo/18.csv'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/18.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/data/demo/18.jpg'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/output.csv' -> '/home/arman05/Desktop/tf-faster-rcnn/data/demo/output.csv'\n"
     ]
    }
   ],
   "source": [
    "mv  -v ~/Desktop/face-classification/results/* ~/Desktop/tf-faster-rcnn/data/demo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arman05/Desktop/tf-faster-rcnn/data/demo\n"
     ]
    }
   ],
   "source": [
    "cd ../../tf-faster-rcnn/data/demo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.csv\t12.csv\t14.csv\t16.csv\t18.csv\n",
      "11.csv\t13.csv\t15.csv\t17.csv\toutput.csv\n"
     ]
    }
   ],
   "source": [
    "!ls *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.jpg\t11.jpg\t12.jpg\t13.jpg\t14.jpg\t15.jpg\t16.jpg\t17.jpg\t18.jpg\n"
     ]
    }
   ],
   "source": [
    "!ls *.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for putting all images in an array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import glob\n",
    "# images = []\n",
    "# for filename in glob.glob('*.jpg'): # i.e. jpg images\n",
    "#     im=Image.open(filename)\n",
    "#     images.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd data/demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# vidcap = cv2.VideoCapture('video.mp4')\n",
    "# def getFrame(sec):\n",
    "#     vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "#     hasFrames,image = vidcap.read()\n",
    "#     if hasFrames:\n",
    "#         cv2.imwrite(\"image\"+str(count)+\".jpg\", image)     # save frame as JPG file\n",
    "#     return hasFrames\n",
    "# sec = 0\n",
    "# frameRate = 0.5 #//it will capture image in each 0.5 second\n",
    "# count=1\n",
    "# success = getFrame(sec)\n",
    "# while success:\n",
    "#     count = count + 1\n",
    "#     sec = sec + frameRate\n",
    "#     sec = round(sec, 2)\n",
    "#     success = getFrame(sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm *.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arman05/Desktop/tf-faster-rcnn\n"
     ]
    }
   ],
   "source": [
    "cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arman05/anaconda3/envs/frcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/arman05/anaconda3/envs/frcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/arman05/anaconda3/envs/frcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/arman05/anaconda3/envs/frcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/arman05/anaconda3/envs/frcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/arman05/anaconda3/envs/frcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/arman05/anaconda3/envs/frcnn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/arman05/anaconda3/envs/frcnn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/arman05/anaconda3/envs/frcnn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/arman05/anaconda3/envs/frcnn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/arman05/anaconda3/envs/frcnn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/arman05/anaconda3/envs/frcnn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:tensorflow:From ./tools/demo.py:149: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From ./tools/demo.py:153: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2020-04-08 15:34:58.609329: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-04-08 15:34:58.635655: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1800000000 Hz\n",
      "2020-04-08 15:34:58.636213: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564231d4c6b0 executing computations on platform Host. Devices:\n",
      "2020-04-08 15:34:58.636265: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2020-04-08 15:34:58.636433: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:tensorflow:From /home/arman05/Desktop/tf-faster-rcnn/tools/../lib/nets/network.py:388: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/arman05/Desktop/tf-faster-rcnn/tools/../lib/nets/network.py:413: The name tf.no_regularizer is deprecated. Please use tf.compat.v1.no_regularizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/arman05/Desktop/tf-faster-rcnn/tools/../lib/nets/vgg16.py:27: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b3c7fed10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b3c7fed10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b3c7fec90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b3c7fec90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3b3c86bb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3b3c86bb90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b3c7febd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b3c7febd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b3c9b01d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b3c9b01d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3b3c9b01d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3b3c9b01d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b38749a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b38749a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b386fecd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b386fecd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b3c817f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b3c817f90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3b3c86ba90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3b3c86ba90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b38759290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b38759290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b3c82c1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b3c82c1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b3878a9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b3878a9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3b3875b550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3b3875b550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b3878a8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b3878a8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b385b7310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b385b7310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b386b0210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b386b0210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/arman05/Desktop/tf-faster-rcnn/tools/../lib/nets/network.py:213: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b3c9b0750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b3c9b0750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b387a82d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b387a82d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b385e7bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3b385e7bd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/arman05/Desktop/tf-faster-rcnn/tools/../lib/layer_utils/proposal_layer.py:75: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/arman05/Desktop/tf-faster-rcnn/tools/../lib/nets/network.py:155: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3b3851c850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3b3851c850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/arman05/anaconda3/envs/frcnn/lib/python3.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3b3851c8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3b3851c8d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3b3851c590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3b3851c590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3b38513d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3b38513d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3b3844aad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3b3844aad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3b383ab210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3b383ab210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From ./tools/demo.py:163: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/arman05/anaconda3/envs/frcnn/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "2020-04-08 15:35:01.294587: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Loaded network output/vgg16/voc_2007_trainval/default/vgg16_faster_rcnn_iter_70000.ckpt\n",
      "['11.jpg', '15.jpg', '13.jpg', '17.jpg', '16.jpg', '14.jpg', '12.jpg', '10.jpg', '18.jpg']\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/11.jpg\n",
      "Detection took 3.993s for 300 object proposals\n",
      "person : 9\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/15.jpg\n",
      "Detection took 2.450s for 300 object proposals\n",
      "person : 1\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/13.jpg\n",
      "Detection took 2.839s for 300 object proposals\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/17.jpg\n",
      "Detection took 3.591s for 300 object proposals\n",
      "person : 3\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/16.jpg\n",
      "Detection took 4.521s for 300 object proposals\n",
      "person : 3\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/14.jpg\n",
      "Detection took 4.696s for 300 object proposals\n",
      "person : 2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/12.jpg\n",
      "Detection took 4.133s for 300 object proposals\n",
      "person : 20\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/10.jpg\n",
      "Detection took 4.832s for 300 object proposals\n",
      "person : 4\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for data/demo/18.jpg\n",
      "Detection took 4.368s for 300 object proposals\n",
      "person : 3\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 ./tools/demo.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arman05/Desktop/tf-faster-rcnn/data/demo\n"
     ]
    }
   ],
   "source": [
    "cd data/demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arman05/Desktop/tf-faster-rcnn\n"
     ]
    }
   ],
   "source": [
    "cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "renamed '/home/arman05/Desktop/tf-faster-rcnn/results/result_10.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/Gender+Person/result_10.jpg'\n",
      "renamed '/home/arman05/Desktop/tf-faster-rcnn/results/result_11.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/Gender+Person/result_11.jpg'\n",
      "renamed '/home/arman05/Desktop/tf-faster-rcnn/results/result_12.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/Gender+Person/result_12.jpg'\n",
      "renamed '/home/arman05/Desktop/tf-faster-rcnn/results/result_13.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/Gender+Person/result_13.jpg'\n",
      "renamed '/home/arman05/Desktop/tf-faster-rcnn/results/result_14.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/Gender+Person/result_14.jpg'\n",
      "renamed '/home/arman05/Desktop/tf-faster-rcnn/results/result_15.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/Gender+Person/result_15.jpg'\n",
      "renamed '/home/arman05/Desktop/tf-faster-rcnn/results/result_16.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/Gender+Person/result_16.jpg'\n",
      "renamed '/home/arman05/Desktop/tf-faster-rcnn/results/result_17.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/Gender+Person/result_17.jpg'\n",
      "renamed '/home/arman05/Desktop/tf-faster-rcnn/results/result_18.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/Gender+Person/result_18.jpg'\n"
     ]
    }
   ],
   "source": [
    "mv  -v ~/Desktop/tf-faster-rcnn/results/* ~/Desktop/tf-faster-rcnn/Gender+Person/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# from IPython.display import display, Image\n",
    "\n",
    "# from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arman05/anaconda3/envs/frcnn/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# import PIL\n",
    "# import sys\n",
    "# images = [ PIL.Image.open(f) for f in glob('results/*') ]\n",
    "\n",
    "# def img2array(im):\n",
    "#     if im.mode != 'RGB':\n",
    "#         im = im.convert(mode='RGB')\n",
    "#     return np.fromstring(im.tobytes(), dtype='uint8').reshape((im.size[1], im.size[0], 3))\n",
    "\n",
    "# np_images = [ img2array(im) for im in images ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img in np_images:\n",
    "#     plt.figure()\n",
    "#     plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
