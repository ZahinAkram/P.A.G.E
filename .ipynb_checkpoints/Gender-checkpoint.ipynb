{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arman\\Desktop\\Gender_Detection\n"
     ]
    }
   ],
   "source": [
    "cd Gender_Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '*.jpg': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# !rm *.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arman05/Desktop\n"
     ]
    }
   ],
   "source": [
    "# cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp ~/Desktop/Input_Test_Images/* ~/Desktop/face-classification/test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying images in test/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arman\\Anaconda3\\envs\\capstone_demo\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.22.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Arman\\Anaconda3\\envs\\capstone_demo\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.22.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]\n",
      "  3%|2         | 1/34 [00:01<00:58,  1.77s/it]\n",
      "  6%|5         | 2/34 [00:05<01:15,  2.35s/it]\n",
      "  9%|8         | 3/34 [00:18<02:48,  5.42s/it]\n",
      " 12%|#1        | 4/34 [00:20<02:11,  4.38s/it]\n",
      " 15%|#4        | 5/34 [00:21<01:43,  3.57s/it]\n",
      " 18%|#7        | 6/34 [00:24<01:33,  3.35s/it]\n",
      " 24%|##3       | 8/34 [00:25<01:05,  2.51s/it]\n",
      " 26%|##6       | 9/34 [00:28<01:08,  2.74s/it]\n",
      " 29%|##9       | 10/34 [00:29<00:49,  2.08s/it]\n",
      " 32%|###2      | 11/34 [00:29<00:37,  1.61s/it]\n",
      " 35%|###5      | 12/34 [00:32<00:39,  1.77s/it]\n",
      " 38%|###8      | 13/34 [00:34<00:41,  1.95s/it]\n",
      " 41%|####1     | 14/34 [00:36<00:37,  1.87s/it]\n",
      " 44%|####4     | 15/34 [00:36<00:25,  1.36s/it]\n",
      " 47%|####7     | 16/34 [00:36<00:20,  1.15s/it]\n",
      " 50%|#####     | 17/34 [00:38<00:21,  1.27s/it]\n",
      " 53%|#####2    | 18/34 [00:40<00:23,  1.49s/it]\n",
      " 56%|#####5    | 19/34 [00:41<00:20,  1.35s/it]\n",
      " 59%|#####8    | 20/34 [00:44<00:23,  1.68s/it]\n",
      " 62%|######1   | 21/34 [00:52<00:50,  3.86s/it]\n",
      " 65%|######4   | 22/34 [00:59<00:55,  4.60s/it]\n",
      " 71%|#######   | 24/34 [01:00<00:34,  3.43s/it]\n",
      " 74%|#######3  | 25/34 [01:02<00:26,  2.93s/it]\n",
      " 79%|#######9  | 27/34 [01:06<00:18,  2.60s/it]\n",
      " 82%|########2 | 28/34 [01:08<00:15,  2.63s/it]\n",
      " 85%|########5 | 29/34 [01:11<00:14,  2.81s/it]\n",
      " 88%|########8 | 30/34 [01:14<00:10,  2.74s/it]\n",
      " 91%|#########1| 31/34 [01:15<00:06,  2.10s/it]\n",
      " 94%|#########4| 32/34 [01:18<00:04,  2.40s/it]\n",
      " 97%|#########7| 33/34 [01:22<00:02,  2.84s/it]\n",
      "100%|##########| 34/34 [01:23<00:00,  2.38s/it]\n",
      "100%|##########| 34/34 [01:23<00:00,  2.46s/it]\n"
     ]
    }
   ],
   "source": [
    "!python pred.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arman05/Desktop/face-classification/test\n"
     ]
    }
   ],
   "source": [
    "cd test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arman05/Desktop/face-classification\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "renamed '/home/arman05/Desktop/face-classification/results/10.csv' -> '/home/arman05/Desktop/tf-faster-rcnn/Only_Gender/10.csv'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/10.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/Only_Gender/10.jpg'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/11.csv' -> '/home/arman05/Desktop/tf-faster-rcnn/Only_Gender/11.csv'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/11.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/Only_Gender/11.jpg'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/12.csv' -> '/home/arman05/Desktop/tf-faster-rcnn/Only_Gender/12.csv'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/12.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/Only_Gender/12.jpg'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/13.csv' -> '/home/arman05/Desktop/tf-faster-rcnn/Only_Gender/13.csv'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/13.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/Only_Gender/13.jpg'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/14.csv' -> '/home/arman05/Desktop/tf-faster-rcnn/Only_Gender/14.csv'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/14.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/Only_Gender/14.jpg'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/15.csv' -> '/home/arman05/Desktop/tf-faster-rcnn/Only_Gender/15.csv'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/15.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/Only_Gender/15.jpg'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/16.csv' -> '/home/arman05/Desktop/tf-faster-rcnn/Only_Gender/16.csv'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/16.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/Only_Gender/16.jpg'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/17.csv' -> '/home/arman05/Desktop/tf-faster-rcnn/Only_Gender/17.csv'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/17.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/Only_Gender/17.jpg'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/18.csv' -> '/home/arman05/Desktop/tf-faster-rcnn/Only_Gender/18.csv'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/18.jpg' -> '/home/arman05/Desktop/tf-faster-rcnn/Only_Gender/18.jpg'\n",
      "renamed '/home/arman05/Desktop/face-classification/results/output.csv' -> '/home/arman05/Desktop/tf-faster-rcnn/Only_Gender/output.csv'\n"
     ]
    }
   ],
   "source": [
    "mv  -v ~/Desktop/face-classification/results/* ~/Desktop/tf-faster-rcnn/Only_Gender/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arman05/Desktop/tf-faster-rcnn/Only_Gender\n"
     ]
    }
   ],
   "source": [
    "cd ../tf-faster-rcnn/Only_Gender/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# from IPython.display import display, Image\n",
    "\n",
    "# from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arman05/anaconda3/envs/frcnn/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# import PIL\n",
    "# import sys\n",
    "# images = [ PIL.Image.open(f) for f in glob('results/*') ]\n",
    "\n",
    "# def img2array(im):\n",
    "#     if im.mode != 'RGB':\n",
    "#         im = im.convert(mode='RGB')\n",
    "#     return np.fromstring(im.tobytes(), dtype='uint8').reshape((im.size[1], im.size[0], 3))\n",
    "\n",
    "# np_images = [ img2array(im) for im in images ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img in np_images:\n",
    "#     plt.figure()\n",
    "#     plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
